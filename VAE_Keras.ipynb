{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, LeakyReLU, Lambda, Conv2D, BatchNormalization\n",
    "from keras.losses import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sampling layer\n",
    "def sampling(z):\n",
    "    z_mean, z_log_var = z\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoder template\n",
    "def Encoder():\n",
    "    # You can modify the architecture for your own design\n",
    "    # The following is just a simple example\n",
    "    x = Dense(512)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    # The sampling layer\n",
    "    z_mean = Dense(128, name='z_mean')(x)\n",
    "    z_log_var = Dense(128, name='z_log_var')(x)\n",
    "    \n",
    "    return z_mean, z_log_var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoder template\n",
    "def Decoder(x):\n",
    "    # You can modify the architecture for your own design\n",
    "    # The following is just a simple example\n",
    "    \n",
    "    x = Dense(512)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define KL loss\n",
    "def KL_Loss(z_mean, z_log_var):\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    print(kl_loss)\n",
    "    \n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reconstruction loss\n",
    "def Reconstruction_Loss(inputs, outputs):\n",
    "    loss = mean_squared_error(inputs, outputs)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full autoencoder\n",
    "def Autoencoder():\n",
    "    inputs = Input((1024,))\n",
    "    z_mean, z_log_var = Encoder()(inputs)\n",
    "    z = Lambda(sampling, name='z')([z_mean, z_log_var])\n",
    "    outputs = Decoder(z)\n",
    "    \n",
    "    # You can modify the following for your own design\n",
    "    beta = 1.0\n",
    "    \n",
    "    VAE = Model(inputs, outputs)\n",
    "    \n",
    "    VAE_Loss = K.mean(Reconstruction_Loss(inputs, outputs) * 1024 + KL_Loss(z_mean, z_log_var) * beta)\n",
    "    VAE.add_loss(VAE_Loss)\n",
    "    VAE.compile(optimizer='adam')\n",
    "    \n",
    "    Encoder_ = Model(inputs, z)\n",
    "    \n",
    "    return VAE, Encoder_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer leaky_re_lu_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.core.Dense'>. Full input: [<keras.layers.core.Dense object at 0x000001EFBEA67EF0>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m--> 474\u001b[1;33m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.layers.core.Dense'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e922ce88ba4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mVAE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEncoder_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVAE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-97478452a4a1>\u001b[0m in \u001b[0;36mAutoencoder\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_log_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'z'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_log_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c7899cb0fafe>\u001b[0m in \u001b[0;36mEncoder\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# The following is just a simple example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# The sampling layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    283\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer leaky_re_lu_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.core.Dense'>. Full input: [<keras.layers.core.Dense object at 0x000001EFBEA67EF0>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "VAE, Encoder_ = Autoencoder()\n",
    "print(VAE.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49661779 0.79254345 0.31734548 ... 0.74377957 0.77536782 0.07223718]\n",
      " [0.14895057 0.04332683 0.96541642 ... 0.53211502 0.25367769 0.99844478]\n",
      " [0.28139611 0.5437912  0.40258143 ... 0.98637925 0.72418104 0.14062972]\n",
      " ...\n",
      " [0.80646686 0.06094832 0.18961759 ... 0.94441179 0.9026205  0.30932427]\n",
      " [0.48568428 0.06456302 0.39074083 ... 0.70393537 0.82346195 0.92771353]\n",
      " [0.57645433 0.27057066 0.18872184 ... 0.74669469 0.74966826 0.66129119]]\n"
     ]
    }
   ],
   "source": [
    "Data = np.random.rand(100, 1024)\n",
    "print(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.4665\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 42.2921\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 0s 240us/step - loss: 42.3233\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.7681\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 45.0777\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 43.9761\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 46.5115\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 44.3698\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 44.1891\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.2108\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 43.3361\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 0s 240us/step - loss: 42.8163\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.3087\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.5870\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.7303\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 43.5403\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.1614\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.5317\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.4640\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.9052\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 43.2519\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.3312\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.6042\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.7685\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 0s 260us/step - loss: 40.8703\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.2452\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.4531\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.7868\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.1623\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.0526\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.5826\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.2873\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.7869\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 42.8828\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.1926\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 45.1392\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 44.8836\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 44.1350\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.8301\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.8830\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.4519\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 0s 240us/step - loss: 43.2659\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.3144\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.0744\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.1453\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.0888\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.5394\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.5765\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 45.4047\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.4267\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.0003\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 43.3628\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 42.4405\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 43.3296\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 43.7225\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.1073\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 43.3965\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.8409\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.4057\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.9894\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.9941\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 44.4676\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.3273\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.2081\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.1901\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.4374\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 43.1205\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 42.8517\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.8090\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.7475\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.7434\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.6639\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 42.3608\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.1925\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.8793\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.9326\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.7423\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.8958\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.3728\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.9729\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 38.7370\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.2816\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.4874\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.4478\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 0s 240us/step - loss: 40.3708\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 0s 210us/step - loss: 41.3799\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.9970\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.9058\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 40.8876\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.2021\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 40.1697\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.7092\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.4257\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.1609\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 42.7959\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.4507\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.3608\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.2920\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 41.5107\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.4704\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.6974\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 42.5210\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 42.7344\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 42.7215\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.9480\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.9463\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.5513\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 42.7440\n",
      "Epoch 109/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 43.4836\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.6148\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 42.7515\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.5408\n",
      "Epoch 113/500\n",
      "100/100 [==============================] - 0s 240us/step - loss: 41.6166\n",
      "Epoch 114/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.9128\n",
      "Epoch 115/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.5514\n",
      "Epoch 116/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 41.9276\n",
      "Epoch 117/500\n",
      "100/100 [==============================] - 0s 240us/step - loss: 40.6262\n",
      "Epoch 118/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.4172\n",
      "Epoch 119/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.8220\n",
      "Epoch 120/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 40.4669\n",
      "Epoch 121/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.5392\n",
      "Epoch 122/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.3151\n",
      "Epoch 123/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.3723\n",
      "Epoch 124/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 41.7835\n",
      "Epoch 125/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.1229\n",
      "Epoch 126/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.7042\n",
      "Epoch 127/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.4181\n",
      "Epoch 128/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.2353\n",
      "Epoch 129/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 40.1979\n",
      "Epoch 130/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.2704\n",
      "Epoch 131/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.2019\n",
      "Epoch 132/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.1506\n",
      "Epoch 133/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.9895\n",
      "Epoch 134/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.9956\n",
      "Epoch 135/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.2018\n",
      "Epoch 136/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.1542\n",
      "Epoch 137/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.3572\n",
      "Epoch 138/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.7433\n",
      "Epoch 139/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.7697\n",
      "Epoch 140/500\n",
      "100/100 [==============================] - 0s 220us/step - loss: 40.4313\n",
      "Epoch 141/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 42.2432\n",
      "Epoch 142/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.7707\n",
      "Epoch 143/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.0135\n",
      "Epoch 144/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.7999\n",
      "Epoch 145/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 43.4141\n",
      "Epoch 146/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.2816\n",
      "Epoch 147/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 42.8895\n",
      "Epoch 148/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 43.6615\n",
      "Epoch 149/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.8172\n",
      "Epoch 150/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.3298\n",
      "Epoch 151/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.3617\n",
      "Epoch 152/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.7231\n",
      "Epoch 153/500\n",
      "100/100 [==============================] - 0s 199us/step - loss: 42.2148\n",
      "Epoch 154/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 42.2320\n",
      "Epoch 155/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 42.1348\n",
      "Epoch 156/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 44.6752\n",
      "Epoch 157/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 44.0873\n",
      "Epoch 158/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.7533\n",
      "Epoch 159/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 43.2118\n",
      "Epoch 160/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 41.9526\n",
      "Epoch 161/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.5172\n",
      "Epoch 162/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.8117\n",
      "Epoch 163/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.7960\n",
      "Epoch 164/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 43.8184\n",
      "Epoch 165/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.2381\n",
      "Epoch 166/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.8780\n",
      "Epoch 167/500\n",
      "100/100 [==============================] - 0s 240us/step - loss: 41.3215\n",
      "Epoch 168/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.5602\n",
      "Epoch 169/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.0416\n",
      "Epoch 170/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.0357\n",
      "Epoch 171/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.9736\n",
      "Epoch 172/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 37.3954\n",
      "Epoch 173/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.1697\n",
      "Epoch 174/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.4367\n",
      "Epoch 175/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.3235\n",
      "Epoch 176/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.6313\n",
      "Epoch 177/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.5431\n",
      "Epoch 178/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.5054\n",
      "Epoch 179/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 42.7670\n",
      "Epoch 180/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 40.6498\n",
      "Epoch 181/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 41.3757\n",
      "Epoch 182/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 41.4176\n",
      "Epoch 183/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 40.6353\n",
      "Epoch 184/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.5174\n",
      "Epoch 185/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.5858\n",
      "Epoch 186/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.3973\n",
      "Epoch 187/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.3477\n",
      "Epoch 188/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 39.0510\n",
      "Epoch 189/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.3378\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 249us/step - loss: 41.5444\n",
      "Epoch 191/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 40.0029\n",
      "Epoch 192/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.8655\n",
      "Epoch 193/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.7719\n",
      "Epoch 194/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.5678\n",
      "Epoch 195/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.2500\n",
      "Epoch 196/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 40.2528\n",
      "Epoch 197/500\n",
      "100/100 [==============================] - 0s 280us/step - loss: 40.6249\n",
      "Epoch 198/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.2656\n",
      "Epoch 199/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.2482\n",
      "Epoch 200/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.4508\n",
      "Epoch 201/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.9427\n",
      "Epoch 202/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.0581\n",
      "Epoch 203/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.1669\n",
      "Epoch 204/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.3422\n",
      "Epoch 205/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 42.5194\n",
      "Epoch 206/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.0060\n",
      "Epoch 207/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 39.9441\n",
      "Epoch 208/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.4946\n",
      "Epoch 209/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.6042\n",
      "Epoch 210/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.6845\n",
      "Epoch 211/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.5637\n",
      "Epoch 212/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.0624\n",
      "Epoch 213/500\n",
      "100/100 [==============================] - 0s 260us/step - loss: 39.9354\n",
      "Epoch 214/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.4945\n",
      "Epoch 215/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.2762\n",
      "Epoch 216/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.7256\n",
      "Epoch 217/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.1668\n",
      "Epoch 218/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.6271\n",
      "Epoch 219/500\n",
      "100/100 [==============================] - 0s 240us/step - loss: 44.1714\n",
      "Epoch 220/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 43.9344\n",
      "Epoch 221/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.8007\n",
      "Epoch 222/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.2105\n",
      "Epoch 223/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.6007\n",
      "Epoch 224/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.1162\n",
      "Epoch 225/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.0819\n",
      "Epoch 226/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.0419\n",
      "Epoch 227/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.7469\n",
      "Epoch 228/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.2273\n",
      "Epoch 229/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 40.4496\n",
      "Epoch 230/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.7549\n",
      "Epoch 231/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.5050\n",
      "Epoch 232/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.5094\n",
      "Epoch 233/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 39.1609\n",
      "Epoch 234/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 39.6508\n",
      "Epoch 235/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.1048\n",
      "Epoch 236/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.6874\n",
      "Epoch 237/500\n",
      "100/100 [==============================] - 0s 220us/step - loss: 39.1482\n",
      "Epoch 238/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 40.5336\n",
      "Epoch 239/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 38.6138\n",
      "Epoch 240/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.6448\n",
      "Epoch 241/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.6991\n",
      "Epoch 242/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 40.7385\n",
      "Epoch 243/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.2175\n",
      "Epoch 244/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 43.6214\n",
      "Epoch 245/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.1191\n",
      "Epoch 246/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.5039\n",
      "Epoch 247/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.6408\n",
      "Epoch 248/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.7887\n",
      "Epoch 249/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.0004\n",
      "Epoch 250/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.1482\n",
      "Epoch 251/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.2891\n",
      "Epoch 252/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 40.2376\n",
      "Epoch 253/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.6677\n",
      "Epoch 254/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.0282\n",
      "Epoch 255/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.9132\n",
      "Epoch 256/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.8673\n",
      "Epoch 257/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.8671\n",
      "Epoch 258/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.3728\n",
      "Epoch 259/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 43.0741\n",
      "Epoch 260/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.6414\n",
      "Epoch 261/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.8922\n",
      "Epoch 262/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 40.3107\n",
      "Epoch 263/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 43.2551\n",
      "Epoch 264/500\n",
      "100/100 [==============================] - 0s 329us/step - loss: 41.6325\n",
      "Epoch 265/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.1599\n",
      "Epoch 266/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.1034\n",
      "Epoch 267/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 39.8995\n",
      "Epoch 268/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.7177\n",
      "Epoch 269/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.6884\n",
      "Epoch 270/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.6816\n",
      "Epoch 271/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.5366\n",
      "Epoch 272/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.8835\n",
      "Epoch 273/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 41.5326\n",
      "Epoch 274/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 42.0470\n",
      "Epoch 275/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.6729\n",
      "Epoch 276/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.4758\n",
      "Epoch 277/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.3315\n",
      "Epoch 278/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.5272\n",
      "Epoch 279/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.2347\n",
      "Epoch 280/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.7417\n",
      "Epoch 281/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 39.5957\n",
      "Epoch 282/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 37.9472\n",
      "Epoch 283/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.0820\n",
      "Epoch 284/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 37.6724\n",
      "Epoch 285/500\n",
      "100/100 [==============================] - 0s 280us/step - loss: 41.8194\n",
      "Epoch 286/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.0607\n",
      "Epoch 287/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.7788\n",
      "Epoch 288/500\n",
      "100/100 [==============================] - 0s 309us/step - loss: 39.8039\n",
      "Epoch 289/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.3249\n",
      "Epoch 290/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.7704\n",
      "Epoch 291/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.2848\n",
      "Epoch 292/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.0376\n",
      "Epoch 293/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.8225\n",
      "Epoch 294/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.4337\n",
      "Epoch 295/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 41.9578\n",
      "Epoch 296/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 42.4610\n",
      "Epoch 297/500\n",
      "100/100 [==============================] - 0s 209us/step - loss: 43.2534\n",
      "Epoch 298/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.5638\n",
      "Epoch 299/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.3519\n",
      "Epoch 300/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.2772\n",
      "Epoch 301/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 43.4835\n",
      "Epoch 302/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.2538\n",
      "Epoch 303/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.2985\n",
      "Epoch 304/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.9270\n",
      "Epoch 305/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.5659\n",
      "Epoch 306/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.7913\n",
      "Epoch 307/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.4108\n",
      "Epoch 308/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.9038\n",
      "Epoch 309/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 42.1299\n",
      "Epoch 310/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.0024\n",
      "Epoch 311/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 40.3517\n",
      "Epoch 312/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.3043\n",
      "Epoch 313/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.7811\n",
      "Epoch 314/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.4822\n",
      "Epoch 315/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.1305\n",
      "Epoch 316/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.3449\n",
      "Epoch 317/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.7749\n",
      "Epoch 318/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.3996\n",
      "Epoch 319/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.9289\n",
      "Epoch 320/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 41.5326\n",
      "Epoch 321/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.7309\n",
      "Epoch 322/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 44.3082\n",
      "Epoch 323/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 42.9851\n",
      "Epoch 324/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 41.1330\n",
      "Epoch 325/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 44.7665\n",
      "Epoch 326/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 40.4249\n",
      "Epoch 327/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.2674\n",
      "Epoch 328/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.5674\n",
      "Epoch 329/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 41.9213\n",
      "Epoch 330/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 42.5185\n",
      "Epoch 331/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 41.9788\n",
      "Epoch 332/500\n",
      "100/100 [==============================] - 0s 299us/step - loss: 42.1686\n",
      "Epoch 333/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 41.5051\n",
      "Epoch 334/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.0456\n",
      "Epoch 335/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.7397\n",
      "Epoch 336/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.0934\n",
      "Epoch 337/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 41.7182\n",
      "Epoch 338/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.2350\n",
      "Epoch 339/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.2897\n",
      "Epoch 340/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.4565\n",
      "Epoch 341/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 39.9840\n",
      "Epoch 342/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.4233\n",
      "Epoch 343/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.3260\n",
      "Epoch 344/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.4975\n",
      "Epoch 345/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.6511\n",
      "Epoch 346/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.1031\n",
      "Epoch 347/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 39.9754\n",
      "Epoch 348/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.6721\n",
      "Epoch 349/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.8746\n",
      "Epoch 350/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.7886\n",
      "Epoch 351/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 39.4367\n",
      "Epoch 352/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.9573\n",
      "Epoch 353/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.6196\n",
      "Epoch 354/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 39.5871\n",
      "Epoch 355/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.9908\n",
      "Epoch 356/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.0749\n",
      "Epoch 357/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.7888\n",
      "Epoch 358/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.2480\n",
      "Epoch 359/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.4234\n",
      "Epoch 360/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.4551\n",
      "Epoch 361/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.1719\n",
      "Epoch 362/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 38.3820\n",
      "Epoch 363/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.7298\n",
      "Epoch 364/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.5679\n",
      "Epoch 365/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.3073\n",
      "Epoch 366/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 37.9892\n",
      "Epoch 367/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 41.2693\n",
      "Epoch 368/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.6282\n",
      "Epoch 369/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.9971\n",
      "Epoch 370/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.6393\n",
      "Epoch 371/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.2288\n",
      "Epoch 372/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 40.2218\n",
      "Epoch 373/500\n",
      "100/100 [==============================] - 0s 230us/step - loss: 41.6908\n",
      "Epoch 374/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.9009\n",
      "Epoch 375/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.4166\n",
      "Epoch 376/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.8877\n",
      "Epoch 377/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.5689\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 249us/step - loss: 40.4251\n",
      "Epoch 379/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.8443\n",
      "Epoch 380/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.4692\n",
      "Epoch 381/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.6406\n",
      "Epoch 382/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.6440\n",
      "Epoch 383/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.1810\n",
      "Epoch 384/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 39.9849\n",
      "Epoch 385/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 40.1582\n",
      "Epoch 386/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.7426\n",
      "Epoch 387/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.7563\n",
      "Epoch 388/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.7197\n",
      "Epoch 389/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 41.4330\n",
      "Epoch 390/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.4220\n",
      "Epoch 391/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.1055\n",
      "Epoch 392/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.3621\n",
      "Epoch 393/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.3032\n",
      "Epoch 394/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.2176\n",
      "Epoch 395/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.0628\n",
      "Epoch 396/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.9250\n",
      "Epoch 397/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.0259\n",
      "Epoch 398/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.4883\n",
      "Epoch 399/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 39.7341\n",
      "Epoch 400/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.7520\n",
      "Epoch 401/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.9207\n",
      "Epoch 402/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.8295\n",
      "Epoch 403/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.9865\n",
      "Epoch 404/500\n",
      "100/100 [==============================] - 0s 260us/step - loss: 38.5513\n",
      "Epoch 405/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.1286\n",
      "Epoch 406/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.9733\n",
      "Epoch 407/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.0792\n",
      "Epoch 408/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.1356\n",
      "Epoch 409/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.0062\n",
      "Epoch 410/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.1941\n",
      "Epoch 411/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.1509\n",
      "Epoch 412/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.9929\n",
      "Epoch 413/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.2979\n",
      "Epoch 414/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.3203\n",
      "Epoch 415/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.1989\n",
      "Epoch 416/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 37.9511\n",
      "Epoch 417/500\n",
      "100/100 [==============================] - 0s 250us/step - loss: 39.3243\n",
      "Epoch 418/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 39.1294\n",
      "Epoch 419/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.2918\n",
      "Epoch 420/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.4911\n",
      "Epoch 421/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.3554\n",
      "Epoch 422/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.5419\n",
      "Epoch 423/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.7015\n",
      "Epoch 424/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.3032\n",
      "Epoch 425/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.9495\n",
      "Epoch 426/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.8729\n",
      "Epoch 427/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 37.6453\n",
      "Epoch 428/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.5489\n",
      "Epoch 429/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 35.8236\n",
      "Epoch 430/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 37.7905\n",
      "Epoch 431/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 39.2095\n",
      "Epoch 432/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.3661\n",
      "Epoch 433/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.3597\n",
      "Epoch 434/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 38.7142\n",
      "Epoch 435/500\n",
      "100/100 [==============================] - 0s 289us/step - loss: 40.2675\n",
      "Epoch 436/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.3240\n",
      "Epoch 437/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 37.8754\n",
      "Epoch 438/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.3578\n",
      "Epoch 439/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.6638\n",
      "Epoch 440/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.2224\n",
      "Epoch 441/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 42.1996\n",
      "Epoch 442/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.7992\n",
      "Epoch 443/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.6878\n",
      "Epoch 444/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.4004\n",
      "Epoch 445/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.5449\n",
      "Epoch 446/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 40.7701\n",
      "Epoch 447/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.6610\n",
      "Epoch 448/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 38.8630\n",
      "Epoch 449/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 41.1386\n",
      "Epoch 450/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 38.5369\n",
      "Epoch 451/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.4804\n",
      "Epoch 452/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.6027\n",
      "Epoch 453/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.4999\n",
      "Epoch 454/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.9861\n",
      "Epoch 455/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 37.7391\n",
      "Epoch 456/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 38.3098\n",
      "Epoch 457/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 37.9865\n",
      "Epoch 458/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.4848\n",
      "Epoch 459/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 37.3256\n",
      "Epoch 460/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 37.2126\n",
      "Epoch 461/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.7523\n",
      "Epoch 462/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 36.8204\n",
      "Epoch 463/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.0769\n",
      "Epoch 464/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 36.9567\n",
      "Epoch 465/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 37.3785\n",
      "Epoch 466/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 36.9847\n",
      "Epoch 467/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 36.5586\n",
      "Epoch 468/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.4847\n",
      "Epoch 469/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 37.3508\n",
      "Epoch 470/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.6355\n",
      "Epoch 471/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.7562\n",
      "Epoch 472/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.7425\n",
      "Epoch 473/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 42.4195\n",
      "Epoch 474/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.5875\n",
      "Epoch 475/500\n",
      "100/100 [==============================] - 0s 279us/step - loss: 42.1239\n",
      "Epoch 476/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 40.0398\n",
      "Epoch 477/500\n",
      "100/100 [==============================] - 0s 259us/step - loss: 39.9529\n",
      "Epoch 478/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.0164\n",
      "Epoch 479/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 40.1944\n",
      "Epoch 480/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.8483\n",
      "Epoch 481/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.3739\n",
      "Epoch 482/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.6825\n",
      "Epoch 483/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 39.7888\n",
      "Epoch 484/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.6952\n",
      "Epoch 485/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.9849\n",
      "Epoch 486/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.8011\n",
      "Epoch 487/500\n",
      "100/100 [==============================] - ETA: 0s - loss: 38.97 - 0s 229us/step - loss: 39.1002\n",
      "Epoch 488/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 38.2008\n",
      "Epoch 489/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.8266\n",
      "Epoch 490/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 42.0289\n",
      "Epoch 491/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 41.0780\n",
      "Epoch 492/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.2378\n",
      "Epoch 493/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 38.7785\n",
      "Epoch 494/500\n",
      "100/100 [==============================] - 0s 229us/step - loss: 38.6087\n",
      "Epoch 495/500\n",
      "100/100 [==============================] - 0s 269us/step - loss: 39.1251\n",
      "Epoch 496/500\n",
      "100/100 [==============================] - 0s 249us/step - loss: 40.2944\n",
      "Epoch 497/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 39.3117\n",
      "Epoch 498/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 38.3216\n",
      "Epoch 499/500\n",
      "100/100 [==============================] - 0s 219us/step - loss: 39.4563\n",
      "Epoch 500/500\n",
      "100/100 [==============================] - 0s 239us/step - loss: 37.8883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e56a99aa90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE.fit(Data, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder_.save(\"VAE_Encoder_Keras.hdf5\")\n",
    "VAE.save(\"VAE_Keras.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
